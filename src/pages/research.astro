---
import BaseLayout from "../layouts/BaseLayout.astro";
import HorizontalCard from "../components/HorizontalCard.astro";
import { getCollection } from "astro:content";
import createSlug from "../lib/createSlug"
import PostLayout from "@layouts/PostLayout.astro";

const posts = (await getCollection("ongoing-projects")).sort((a, b) => b.data.pubDate.valueOf() - a.data.pubDate.valueOf());
const last_posts = posts.slice(1, posts.length);
---

<BaseLayout title="Research" sideBarActiveItemID="research">

  <div class="pb-12 mt-5">
  <div class="text-3xl py-3 font-bold">Research Overview</div>

  <div class="py-2 text-lg leading-relaxed">
    <p>
      My research interests lie at the intersection of <b>Machine Learning</b>, <b>Robotics</b>, and the pursuit of 
      <b>Embodied Artificial General Intelligence (E-AGI)</b>. 
      I am primarily focused on <b>Reinforcement Learning (RL)</b> and its applications to robot learning systems
      that can reason, adapt, and act robustly in the real world.
    </p>

    <!-- <div class="divider my-4"></div> -->

    <!-- Reinforcement Learning Section -->
    <details class="group border border-base-300 rounded-2xl p-4 mb-3">
      <summary class="text-xl font-bold cursor-pointer select-none flex justify-between items-center">
        Reinforcement Learning and Continual Adaptation
        <span class="transition-transform group-open:rotate-90">➤</span>
      </summary>
      <div class="mt-3 space-y-3">
        <p>
          My current research direction focuses on improving <b>generalization</b>, <b>sample efficiency</b>, and 
          <b>lifelong adaptability</b> in RL. 
          I am particularly interested in developing algorithms that can learn continuously from experience,
          adapt to new contexts and users, and leverage human feedback — without explicit task segmentation or manual reward design.
        </p>

        <ul class="list-disc pl-8 space-y-2">
          <li>
            <b>Task-Agnostic Continual RL:</b> I aim to study methods that go beyond mitigating catastrophic forgetting,
            focusing instead on <b>forward transfer</b> — enabling past knowledge to accelerate future learning. 
            My long-term aim is to build <b>task-agnostic agents</b> that evolve continuously in dynamic environments
            without the need for resetting or explicit supervision.
          </li>
          <li>
            <b>Causal Reasoning in RL:</b> I am very interested in exploring how <b>causal representation learning</b> can structure
            the latent spaces of RL agents, improving <b>generalization</b>, <b>explainability</b>, and <b>data efficiency</b>. 
            This involves learning disentangled, causally grounded state representations that allow for transfer across tasks and environments —
            moving closer to generalist robotic intelligence.
          </li>
          <li>
            <b>Equivariance and Symmetry in RL:</b> I am also strongly attracted to <b>equivariant neural architectures</b> and how they
            can encode the underlying symmetries of physical environments (e.g., SE(3) transformations in manipulation). 
            Such inductive biases can dramatically improve generalization across viewpoints and configurations, 
            and are especially promising when combined with continual or causal RL frameworks.
          </li>
        </ul>
      </div>
    </details>

    <!-- Robot Learning Section -->
    <details class="group border border-base-300 rounded-2xl p-4 mb-3">
      <summary class="text-xl font-bold cursor-pointer select-none flex justify-between items-center">
        Robot Learning and Multimodal Perception
        <span class="transition-transform group-open:rotate-90">➤</span>
      </summary>
      <div class="mt-3">
        <p>
          My work also investigates how RL agents can benefit from <b>rich multimodal perception</b>. 
          In particular, I believe the future of robotics lies in <b>tactile sensing</b> — the ability to 
          perceive and react to physical contact with the environment. 
          Integrating tactile and proprioceptive feedback with vision and language will enable more 
          robust, context-aware, and compliant robot behavior.
        </p>
      </div>
    </details>

    <!-- PbRL / IRL Section -->
    <details class="group border border-base-300 rounded-2xl p-4 mb-3">
      <summary class="text-xl font-bold cursor-pointer select-none flex justify-between items-center">
        Preference-based (PbRL) and Inverse RL for Human-Centered Adaptation
        <span class="transition-transform group-open:rotate-90">➤</span>
      </summary>
      <div class="mt-3">
        <p>
          I am increasingly interested in <b>Preference-based (PbRL)</b> and <b>Inverse Reinforcement Learning (IRL)</b> paradigms, 
          where robots learn reward functions from human corrections, demonstrations, or natural language feedback.
          This <b>human-in-the-loop</b> perspective is crucial for developing adaptive, personalized, and trustworthy robot behaviors.
        </p>
      </div>
    </details>

    <!-- Long-term Vision Section -->
    <details class="group border border-base-300 rounded-2xl p-4 mb-3">
      <summary class="text-xl font-bold cursor-pointer select-none flex justify-between items-center">
        Long-Term Vision
        <span class="transition-transform group-open:rotate-90">➤</span>
      </summary>
      <div class="mt-3">
        <p>
          My long-term goal is to contribute to the development of <b>generalist robots</b> capable of 
          <b>robust, adaptive, and lifelong learning behavior</b> across diverse real-world tasks — 
          bridging the gap between <i>learning in simulation</i> and <i>reasoning in the physical world</i>.
        </p>
      </div>
    </details>
  </div>
</div>
  <div>
    <div class="text-3xl w-full font-bold mb-2">Ongoing projects</div>
  
  </div>

    <div class="divider my-0"></div>
    

    {
        last_posts.map((post) => (
        <>
            <HorizontalCard
            title={post.data.title}
            img={post.data.heroImage}
            desc={post.data.description}
            //url={"/projects/" + post.slug}
            url="#"
            target="_self"
            badge={post.data.badge}
            tags={post.data.tags}
            />
            <div class="divider my-0" />
        </>
        ))
    }
</BaseLayout>
