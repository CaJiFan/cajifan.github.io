---
import BaseLayout from "../layouts/BaseLayout.astro";
import HorizontalCard from "../components/HorizontalCard.astro";
import { getCollection } from "astro:content";
import createSlug from "../lib/createSlug"
import PostLayout from "@layouts/PostLayout.astro";

const posts = (await getCollection("ongoing-projects")).sort((a, b) => b.data.pubDate.valueOf() - a.data.pubDate.valueOf());
const last_posts = posts.slice(1, posts.length);
---

<BaseLayout title="Research" sideBarActiveItemID="research">

  <div class="pb-12 mt-5">
  <div class="text-3xl py-3 font-bold">Research Overview</div>

  <div class="py-2 text-lg leading-relaxed">
    <div>
      <p>
        My research interests lie at the intersection of <b>Machine Learning</b>, <b>Robotics</b>, and the pursuit of 
        <b>Embodied Artificial General Intelligence (E-AGI)</b>. 
        I am primarily focused on <b>Reinforcement Learning (RL)</b> and its applications to robot learning systems
        that can reason, adapt, and act robustly in the real world.
      </p>
    </div>
    <div style="margin-top: 0.4em;">
      <p>
        My long-term goal is to contribute to the development of <b>generalist robots</b> capable of 
          <b>robust, adaptive, and lifelong learning behavior</b> across diverse real-world tasks — 
          bridging the gap between <i>learning in simulation</i> and <i>reasoning in the physical world</i>.
      </p>
    </div>
    <br>

    <!-- <div class="divider my-4"></div> -->

    <!-- Reinforcement Learning Section -->
    <details class="group border border-base-300 rounded-2xl p-4 mb-3">
      <summary class="text-xl font-bold cursor-pointer select-none flex justify-between items-center">
        Continual RL
        <span class="transition-transform group-open:rotate-90">➤</span>
      </summary>
      <div class="mt-3 space-y-3">
        <p>
          My current research direction focuses on improving <b>generalization</b>, <b>sample efficiency</b>, and 
          <b>lifelong adaptability</b> in RL. 
          I am particularly interested in developing algorithms that can learn continuously from experience,
          adapt to new contexts and users, and leverage human feedback — without explicit task segmentation or manual reward design.
        </p>
        <p>
          I aim to study methods that go beyond mitigating catastrophic forgetting,
            focusing instead on <b>forward transfer</b> — enabling past knowledge to accelerate future learning — and the <b>loss of plasticity</b>. 
            My long-term aim is to build <b>task-agnostic agents</b> that evolve continuously in dynamic environments
            without the need for resetting or explicit supervision.
        </p>
      </div>
    </details>

    <!-- Causal RL Section -->
    <details class="group border border-base-300 rounded-2xl p-4 mb-3">
      <summary class="text-xl font-bold cursor-pointer select-none flex justify-between items-center">
        Causal Reasoning in RL
        <span class="transition-transform group-open:rotate-90">➤</span>
      </summary>
      <div class="mt-3">
        <p>
         I am very interested in exploring how <b>causal representation learning</b> can structure
            the latent spaces of RL agents, improving <b>generalization</b>, <b>explainability</b>, and <b>data efficiency</b>. 
            This involves learning disentangled, causally grounded state representations that allow for transfer across tasks and environments —
            moving closer to generalist robotic intelligence.
        </p>
      </div>
    </details>

    <!-- Equivariance Section -->
      <details class="group border border-base-300 rounded-2xl p-4 mb-3">
      <summary class="text-xl font-bold cursor-pointer select-none flex justify-between items-center">
        Equivariance and Symmetry in RL
        <span class="transition-transform group-open:rotate-90">➤</span>
      </summary>
      <div class="mt-3">
        <p>
        I am also strongly attracted to <b>equivariant neural architectures</b> and how they
            can encode the underlying symmetries of physical environments (e.g., SE(3) transformations in manipulation). 
            Such inductive biases can dramatically improve generalization across viewpoints and configurations, 
            and are especially promising when combined with continual or causal RL frameworks.
        </p>
      </div>
    </details>


     <!-- PbRL / IRL Section -->
    <details class="group border border-base-300 rounded-2xl p-4 mb-3">
      <summary class="text-xl font-bold cursor-pointer select-none flex justify-between items-center">
        Human-in-the-loop RL
        <span class="transition-transform group-open:rotate-90">➤</span>
      </summary>
      <div class="mt-3">
        <p>
          I am increasingly interested in <b>Preference-based RL (PbRL)</b> and <b>Inverse RL (IRL)</b> paradigms, 
          where robots learn reward functions from human corrections, demonstrations, or natural language feedback.
          This <b>human-in-the-loop</b> perspective is crucial for developing adaptive, personalized, and trustworthy robot behaviors.
        </p>
      </div>
    </details>

    <!-- Robot Learning Section -->
    <details class="group border border-base-300 rounded-2xl p-4 mb-3">
      <summary class="text-xl font-bold cursor-pointer select-none flex justify-between items-center">
        Involving Language and Touch in Robot Learning
        <span class="transition-transform group-open:rotate-90">➤</span>
      </summary>
      <div class="mt-3">
        <p>
          I am interested in how RL agents can benefit from <b>rich multimodal perception</b>, integrating 
          <b>language</b>, vision, proprioceptive and <b>tactile</b> feedback to improve learning and interaction. 
          Language provides a high-level, interpretable signal that can guide exploration and shape task understanding, 
          while tactile sensing allows agents to perceive and respond to forces, contact, and compliance in real-world environments.
        </p>
        <p>
          <!-- By combining these modalities, my goal is to enhance <b>generalization, safety, and adaptability</b> in robotic learning, 
          complementing approaches in <b>continual RL, causal RL, and human-in-the-loop RL</b>.  -->
          This multimodal perspective enables agents to acquire skills more robustly, reason about complex interactions, 
          and align with human intentions in dynamic, unstructured environments.
        </p>
      </div>
    </details>


    <!-- Long-term Vision Section -->
    <!-- <details class="group border border-base-300 rounded-2xl p-4 mb-3">
      <summary class="text-xl font-bold cursor-pointer select-none flex justify-between items-center">
        Long-Term Vision
        <span class="transition-transform group-open:rotate-90">➤</span>
      </summary>
      <div class="mt-3">
        <p>
          My long-term goal is to contribute to the development of <b>generalist robots</b> capable of 
          <b>robust, adaptive, and lifelong learning behavior</b> across diverse real-world tasks — 
          bridging the gap between <i>learning in simulation</i> and <i>reasoning in the physical world</i>.
        </p>
      </div>
    </details> -->
  </div>
</div>
  

<div>
    <div class="text-3xl w-full font-bold mb-2">Ongoing projects</div>
  
  </div>

    <div class="divider my-0"></div>
    

    {
        last_posts.map((post) => (
        <>
            <HorizontalCard
            title={post.data.title}
            img={post.data.heroImage}
            desc={post.data.description}
            //url={"/projects/" + post.slug}
            url="#"
            target="_self"
            badge={post.data.badge}
            tags={post.data.tags}
            />
            <div class="divider my-0" />
        </>
        ))
    }
</BaseLayout>
